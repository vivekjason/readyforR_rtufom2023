[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Welcome to the Ready for R! Workshop Series organised by the Research Training Unit, Faculty of Medicine, Universiti Malaya, Malaysia\n\n\nThis workshop lays the groundwork for addressing key practical aspects of programming and other essential computer skills needed for both research and implementation of statistical methods in three parts. In its first section, the workshop will introduce participants to programming in R and the tidyverse, guidance on coding best practices, and a primer on data wrangling. The second section will explore data visualization, as well as an exploration of both descriptive and inferential statistics using R. The final section of the workshop introduces the concept of regression analysis in R.\n\n\n\nHave a look at the schedule below and download the necessary .qmd files for each session. While I have included solutions- it would be way more beneficial to attempt these yourself first. Lets try to maximise learning in the three sessions.\nIf you are new to R, don’t worry - start off with this deck to learn how to install the software and familiarise yourself with the environment.\n\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n18.8.2023 (Friday)\n8.00 am - 8.30 am\nIntroduction to R\n\n\n\n8.30 am - 9.30 am\nTaking the Wheel #1\n\n\n\n9.30 am - 10.00 am\nBreak\n\n\n\n10.00 am - 10.45 am\nBasics of Tidyverse\n\n\n\n10.45 am - 12.15 pm\nTaking the Wheel #2\n\n\n\n12.15 pm - 12.30 pm\nQ&A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n29.08.2023 (Tuesday)\n8.00 am - 8.30 am\nDescriptive Statistics in R\n\n\n\n8.30 am - 9.30 am\nTaking the Wheel #1\n\n\n\n9.30 am - 10.00 am\nBreak\n\n\n\n10.00 am - 10.45 am\nBasics of ggplot2\n\n\n\n10.45 am - 12.15 pm\nTaking the Wheel #2\n\n\n\n12.15 pm - 1.00 pm\nQ&A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n14.09.2023 (Thursday)\n8.00 am - 8.30 am\nInferential Statistics in R\n\n\n\n8.30 am - 9.30 am\nTaking the Wheel #1\n\n\n\n9.30 am - 10.00 am\nBreak\n\n\n\n10.00 am - 10.45 am\nIntroduction to Regression Analysis\n\n\n\n10.45 am - 12.15 pm\nTaking the Wheel #2\n\n\n\n12.15 pm - 1.00 pm\nQ&A\n\n\n\n\n\n\n\n\n\n\n\n\nVivek Jason\nJason is a gazetting Public Health Physician passionate about epidemiology, infectious diseases and data science. He spends his time between coding, parenting a toddler and pondering the fate of the universe.\n\n\n\nThis course was developed and is maintained by Vivek Jason.\nThe following individuals have contributed to improving the course or materials have been adapted from their courses: R for Applied Epidemiology and Public Health, Stephanie Hicks, Roger D. Peng, Naim Rashid.\nThe course materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Linked and embedded materials are governed by their own licenses. I assume that all external materials used or embedded here are covered under the educational fair use policy. If this is not the case and any material displayed here violates copyright, please let me know and I will remove it."
  },
  {
    "objectID": "introduction_tutorial.html",
    "href": "introduction_tutorial.html",
    "title": "Introduction to R- Tutorial",
    "section": "",
    "text": "Data Structures\n\nExercise 1: Creating a Data Frame\n\nCreate a data frame named ‘employees’ with columns ‘name’, ‘salary’, and ‘department’\nPrint the summary of the data frame.\n\n\n\nShow the solution\nemployees <- data.frame(name = c(\"Alice\", \"Bob\"), salary = c(50000, 60000), department = c(\"HR\", \"Finance\"))\nsummary(employees)\n\n\n\n\nExercise 2: Accessing Elements in a Matrix\n\nCreate a matrix ‘mat’ with the numbers 1 to 12 and 3 rows\nPrint the element in the first row and second column.\n\n\n\nShow the solution\nmat <- matrix(c(1:12), nrow = 3)\nprint(mat[1, 2]) # Output will be 4\n\n\n\n\n\nBasic Data Manipulation\n\nExercise 1: Subsetting Data\n\nCreate a data frame ‘products’ with columns ‘ProductID’, ‘Price’\nPrint the filtered data.\n\n\n\nShow the solution\nproducts <- data.frame(ProductID = c(1, 2, 3), Price = c(15, 25, 30))\nprint(products)\n\n\n\n\nExercise 2: Setting and Getting Working Directory\n\nDetermine your current working directory.\nSet a new working directory to a folder of your choice (e.g., “C:/my_folder”).\nVerify that the working directory has been changed by getting the current working directory again.\n\n\n\nShow the solution\n# Get the current working directory\ngetwd()\n\n# Set a new working directory\nsetwd(\"C:/my_folder\")\n\n# Verify the working directory has been changed\ngetwd() # Output will be \"C:/my_folder\"\n\n\n\n\n\nExercise 3: Calling in Data Using readxl\n\nInstall and load the readxl package\nDownload the quarantine.xlsx file from here and place it in you working directory\nUse the read_excel function to read an Excel file (e.g., “quarantine.xlsx”) from your working directory.\n\n\n\nShow the solution\n# Install the readxl package (if not already installed)\ninstall.packages(\"readxl\")\n\n# Load the readxl package\nlibrary(readxl)\n\n# Read the Excel file\ndata <- read_excel(\"quarantine.xlsx\")\n\n\n\n\nExercise 4: Using Basic Functions\n\nPrint the first 6 rows of the sample data\nPrint the summary of the ‘lattitude’ column.\n\n\n\nShow the solution\ndata(data)\nhead(data)\nsummary(data$lattitude)"
  },
  {
    "objectID": "inferential_stats.html",
    "href": "inferential_stats.html",
    "title": "Inferential Statistics",
    "section": "",
    "text": "Lets get some important packages loaded\n\n\nShow the solution\nrequired_packages <- c(\"tidyverse\", \"lubridate\", \"gtsummary\", \"rstatix\", \"janitor\", \"corrr\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: gtsummary\n\n#Uighur\n\nLoading required package: rstatix\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nLoading required package: janitor\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nLoading required package: corrr\n\n\nAs we mentioned in the Introduction- there are many ways to skin a cat in R.\n\nImporting some data\nLets call in the data:\n\n\nShow the solution\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n\nJust to be consistent we what I said yesterday- before diving into the data always always skim the data first to get a quick feels\n\n\nShow the solution\nc19_df %>% \n  skimr::skim()\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n37165\n\n\nNumber of columns\n15\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate\n0\n1\n10\n10\n0\n1013\n0\n\n\ndate_announced\n0\n1\n10\n10\n0\n1009\n0\n\n\ndate_positive\n0\n1\n10\n10\n0\n1007\n0\n\n\ndate_dose1\n0\n1\n0\n10\n22440\n298\n0\n\n\ndate_dose2\n0\n1\n0\n10\n28038\n267\n0\n\n\ndate_dose3\n0\n1\n0\n10\n35724\n161\n0\n\n\nbrand1\n0\n1\n0\n16\n22440\n8\n0\n\n\nbrand2\n0\n1\n0\n16\n28038\n7\n0\n\n\nbrand3\n0\n1\n0\n16\n35724\n6\n0\n\n\nstate\n0\n1\n5\n17\n0\n16\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n62.66\n16.59\n0\n51\n64\n75\n130\n▁▃▇▃▁\n\n\nmale\n0\n1\n0.58\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nbid\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nmalaysian\n0\n1\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\ncomorb\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\n\n\n\n\n\n\n\n\nrstatix() for inferential statistics\n\n\n\n\n\nInferential statistics is a set of statistical procedures that allows us to draw conclusions about an entire population from a representative sample. The importance of inferential statistics lies in its ability to:\n\nGeneralize about a population: Inferential statistics enables researchers to make predictions or inferences about a population based on the observations made in a sample.\nTest hypotheses: With inferential statistics, researchers can test a hypothesis to determine its statistical significance.\nStudy relationships: It allows researchers to examine the relationships between different variables in a sample and to generalize these relationships to the broader population.\n\nWe will not focus on the mathematics behind inferential statistics but more so the impementation within R. Nontheless, here is a quick summary of commonly used inferential statistical tests and when they are used:\n\nT-tests (One-sample, Independent Two-sample, and Paired): These are used when we want to compare the means of one or two groups. For example, comparing the average height of men and women.\nAnalysis of Variance (ANOVA): ANOVA is used when comparing the means of more than two groups. For example, comparing the average income of people in three different cities.\nChi-square test: The chi-square test is used to determine if there is a significant association between two categorical variables. For example, examining the relationship between gender and voting behavior.\nCorrelation and Regression: Correlation is used to measure the strength and direction of the linear relationship between two variables. Regression is used to predict the value of one variable based on the value of another.\n\nEach test has assumptions that need to be satisfied for the results to be accurate, so it’s essential to choose the right test for the data and research question at hand.\nWhile it is possible to run these tests in base() R, we will skip that in this course since our grounding has all been carried out within the tidyverse(). If you wish to study inferential statistics using base () R you can have a look at this.\nFor the purposes of this course we shall take a deeper look at the rstatix package:\n\nT-test\nUse a formula syntax to specify the numeric and categorical columns for a two sample t-test:\n\n\nShow the solution\nc19_df %>% \n  t_test(age ~ male)\n\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic     df        p\n* <chr> <chr>  <chr>  <int> <int>     <dbl>  <dbl>    <dbl>\n1 age   0      1      15791 21374      9.08 32657. 1.13e-19\n\n\nOr a one-sample t-test\n\n\nShow the solution\nc19_df %>% \n  t_test(age ~ 1, mu = 60)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2         n statistic    df         p\n* <chr> <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n1 age   1      null model 37165      30.9 37164 6.96e-207\n\n\nOr one sample t-tests by group\n\n\nShow the solution\nc19_df %>% \n  group_by(male) %>% \n  t_test(age ~ 1, mu = 60)\n\n\n# A tibble: 2 × 8\n   male .y.   group1 group2         n statistic    df         p\n* <int> <chr> <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n1     0 age   1      null model 15791      26.1 15790 6.14e-147\n2     1 age   1      null model 21374      18.0 21373 5.33e- 72\n\n\n\n\nShapiro-Wilk test\nNote: Sample size must be between 3-5000\n\n\nShow the solution\nc19_df %>% \n  head(500) %>%            # first 500 rows of case linelist, for example only\n  shapiro_test(age)\n\n\n# A tibble: 1 × 3\n  variable statistic             p\n  <chr>        <dbl>         <dbl>\n1 age          0.967 0.00000000413\n\n\n\n\nWilcoxon rank sum test\n\n\nShow the solution\nc19_df %>% \n  wilcox_test(age ~ malaysian)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2    n1    n2 statistic     p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>\n1 age   0      1       4035 33130  31207398     0\n\n\n\n\nKruskal-Wallis test\nAlso known as the Mann-Whitney U test.\n\n\nShow the solution\nc19_df %>% \n  kruskal_test(age ~ state)\n\n\n# A tibble: 1 × 6\n  .y.       n statistic    df         p method        \n* <chr> <int>     <dbl> <int>     <dbl> <chr>         \n1 age   37165     1368.    15 1.58e-282 Kruskal-Wallis\n\n\n\n\nChi-squared test\nThe chi-square test function accepts a table, so first we create a cross-tabulation. There are many ways to create a cross-tabulation but here we use tabyl() from janitor and remove the left-most column of value labels before passing to chisq_test().\n\n\nShow the solution\nc19_df %>% \n  tabyl(malaysian, bid) %>% \n  select(-1) %>% \n  chisq_test()\n\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n1 37165     2461.     0     1 Chi-square test ****    \n\n\n\n\n\ngtsummary() package for Inferential statistics\n\nUse gtsummary if you are looking to add the results of a statistical test to a pretty table that was created with this package. Performing statistical tests of comparison with tbl_summary is done by adding the add_p function to a table and specifying which test to use. It is possible to get p-values corrected for multiple testing by using the add_q function. Run ?tbl_summary for details.\n\n\n\n\n\n\nT-tests\nCompare the difference in means for a continuous variable in two groups. For example, compare the mean age by patient outcome.\n\n\nShow the solution\nc19_df %>% \n  select(age, malaysian) %>%                 # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age ~ \"{mean} ({sd})\",       # specify what statistics to show\n    by = malaysian) %>%                      # specify the grouping variable\n  add_p(age ~ \"t.test\")                      # specify what tests to perform\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0351\n      1, N = 33,1301\n      p-value2\n    \n  \n  \n    age\n49 (14)\n64 (16)\n<0.001\n  \n  \n  \n    \n      1 Mean (SD)\n    \n    \n      2 Welch Two Sample t-test\n    \n  \n\n\n\n\n\n\nWilcoxon rank sum test\nCompare the distribution of a continuous variable in two groups. The default is to use the Wilcoxon rank sum test and the median (IQR) when comparing two groups. However for non-normally distributed data or comparing multiple groups, the Kruskal-wallis test is more appropriate.\n\n\nShow the solution\nc19_df %>% \n  select(age, malaysian) %>%                     # keep variables of interest\n  tbl_summary(                                   # produce summary table\n    statistic = age ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = malaysian) %>%                          # specify the grouping variable\n  add_p(age ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0351\n      1, N = 33,1301\n      p-value2\n    \n  \n  \n    age\n48 (41, 56)\n66 (54, 76)\n<0.001\n  \n  \n  \n    \n      1 Median (IQR)\n    \n    \n      2 Wilcoxon rank sum test\n    \n  \n\n\n\n\n\n\nKruskal-wallis test\nCompare the distribution of a continuous variable in two or more groups, regardless of whether the data is normally distributed.\n\n\nShow the solution\nc19_df %>% \n  select(age, state) %>%                         # keep variables of interest\n  tbl_summary(                                   # produce summary table\n    statistic = age ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = state) %>%                              # specify the grouping variable\n  add_p(age ~ \"kruskal.test\")                    # specify what test to perform\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Johor, N = 4,7411\n      Kedah, N = 2,7561\n      Kelantan, N = 1,4281\n      Melaka, N = 1,2151\n      Negeri Sembilan, N = 1,5461\n      Pahang, N = 1,0371\n      Perak, N = 2,1681\n      Perlis, N = 1991\n      Pulau Pinang, N = 2,0851\n      Sabah, N = 3,2121\n      Sarawak, N = 1,7961\n      Selangor, N = 11,0281\n      Terengganu, N = 9051\n      W.P. Kuala Lumpur, N = 2,8611\n      W.P. Labuan, N = 1591\n      W.P. Putrajaya, N = 291\n      p-value2\n    \n  \n  \n    age\n62 (49, 73)\n64 (52, 76)\n68 (58, 77)\n64 (50, 75)\n66 (55, 76)\n64 (53, 75)\n70 (58, 79)\n71 (60, 81)\n69 (55, 79)\n67 (56, 78)\n71 (59, 79)\n60 (48, 71)\n67 (57, 77)\n63 (50, 74)\n60 (48, 72)\n68 (60, 73)\n<0.001\n  \n  \n  \n    \n      1 Median (IQR)\n    \n    \n      2 Kruskal-Wallis rank sum test\n    \n  \n\n\n\n\n\n\nChi-squared test\nCompare the proportions of a categorical variable in two groups. The default statistical test for add_p() when applied to a categorical variable is to perform a chi-squared test of independence with continuity correction, but if any expected call count is below 5 then a Fisher’s exact test is used.\n\n\nShow the solution\nc19_df %>% \n  select(malaysian, bid) %>% # keep variables of interest\n  tbl_summary(by = bid) %>%  # produce summary table and specify grouping variable\n  add_p()                    # specify what test to perform\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 29,2551\n      1, N = 7,9101\n      p-value2\n    \n  \n  \n    malaysian\n27,297 (93%)\n5,833 (74%)\n<0.001\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson's Chi-squared test\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nCorrelations in R\nCorrelation between numeric variables can be investigated using the tidyverse\ncorrr package. It allows you to compute correlations using Pearson, Kendall tau or Spearman rho. The package creates a table and also has a function to automatically plot the values.\n\n\nShow the solution\ncorrelation_tab <- c19_df %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=as.numeric(date_announced-date),\n         days_admitted=as.numeric(date-date_positive)) %>%\n  select(age, days_delay, days_admitted) %>%                         # keep only columns of interest\n  correlate()                                        # create correlation table (using default pearson)\n\n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\n\nShow the solution\ncorrelation_tab                                                      # print\n\n\n# A tibble: 3 × 4\n  term              age days_delay days_admitted\n  <chr>           <dbl>      <dbl>         <dbl>\n1 age           NA         -0.0994       -0.0308\n2 days_delay    -0.0994    NA            -0.0530\n3 days_admitted -0.0308    -0.0530       NA     \n\n\nPlot a scatteplot of correlations\n\n\nShow the solution\n## plot correlations \nrplot(correlation_tab)\n\n\n\n\n\nFinally you can create a nifty little heatmap. You can calculate a correlation data frame using the correlate() function from corrr, reshape it into a long format with melt(), and then create a heatmap with ggplot2:\n\n\nShow the solution\ncorrelation_tab %>% autoplot(triangular=\"full\") +\n  geom_text(aes(label=round(r, digits=2)), size=4)+\n  theme_minimal(16)\n\n\n\n\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook"
  },
  {
    "objectID": "inferential_stats_tutorial.html",
    "href": "inferential_stats_tutorial.html",
    "title": "Inferential Statistics- Tutorial",
    "section": "",
    "text": "Task 1: Inferential statistics using rstatix\nQuestion: Test if there is a significant difference in age between males and females using the t-test.\nSteps:\n\nInstall and load the rstatix package.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nRecode the “male” variable to factor.\nConduct a t-test to compare the means.\n\n\n\nShow the solution\n# Step 1\n#install.packages(\"rstatix\")\nlibrary(rstatix)\n\n# Step 2\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 3\nc19_df$male <- factor(c19_df$male, levels = c(0, 1), labels = c(\"Female\", \"Male\"))\n\n# Step 4\nc19_df %>% t_test(age ~ male)\n\n\n\n\nTask 2: Inferential statistics using gtsummary\nQuestion: Test if there is a significant difference in age between Malaysians and non-Malaysians using the t-test, and present the results in a table using gtsummary.\nSteps:\n\nRecode the “malaysian” variable to factor (Tip: Use the factor function).\nUse the tbl_summary() function to present the results.\n\n\n\nShow the solution\n# Step 1\nc19_df$malaysian <- factor(c19_df$malaysian, levels = c(0, 1), labels = c(\"Non-Malaysian\", \"Malaysian\"))\n\n# Step 2\nt_test_result <- c19_df %>% \n  select(age, malaysian) %>%                 # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age ~ \"{mean} ({sd})\",       # specify what statistics to show\n    by = malaysian) %>%                      # specify the grouping variable\n  add_p(age ~ \"t.test\") \nt_test_result\n\n\n\n\nTask 3: Correlations using corrr\nQuestion: Compute the correlation between age, male, bid, and malaysian variables, and represent it in a correlation plot (Note: The selection of categorical variables is by design- just to practice the selection and presentation)\nSteps:\n\nInstall and load the corrr package.\nCreate a subset of the data with the selected variables.\nCompute the correlation matrix (Note: Try ?network_plot and see how this can be used)\n\n\n\nShow the solution\n# Step 1\n#install.packages(\"corrr\")\nlibrary(corrr)\n\n# Step 2\ndf_subset <- c19_df %>% select(age, male, bid, malaysian)\n\n# Step 3\ncorrelation_matrix <- df_subset %>% correlate()\n\n# Step 4\ncorrelation_matrix %>% network_plot()\n\n\n\n\n\n\n\nThis would be the outcome if anything was highly correlated in our data."
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "Regression",
    "section": "",
    "text": "Prediction and Forecasting: Regression analysis can help forecast future health trends based on historical data. For example, it can predict the prevalence of a disease based on risk factors.\nIdentifying Risk Factors: Regression analysis can be used to identify risk factors for diseases. For example, it can help determine whether smoking is a significant risk factor for lung cancer.\nCost-effectiveness Analysis: In health economics, regression analysis can help analyze the cost-effectiveness of different treatments or interventions.\nEvaluating Treatment Effects: Regression can be used to compare the effects of different treatments in a population, which can inform healthcare decision-making.\n\nHere are some important regression models used in healthcare data analysis:\n\nLinear Regression: Linear regression is used when the dependent variable is continuous. For example, it could be used to examine the relationship between age (independent variable) and blood pressure (dependent variable).\nLogistic Regression: Logistic regression is used when the dependent variable is binary, i.e., it has two possible outcomes. It is often used to identify risk factors for diseases. For example, it could be used to investigate the impact of various factors (like age, sex, BMI, smoking status) on the likelihood of developing heart disease (Yes/No).\nCox Regression: Cox regression, or proportional hazards regression, is a type of survival analysis used to investigate the effect of various factors on the time a specified event takes to happen. For example, it can be used to study the survival time of patients after being diagnosed with a certain disease.\nPoisson Regression: Poisson regression is used for count data. For instance, it can model the number of hospital admissions over a certain period.\nMultilevel Regression: Multilevel (or hierarchical) regression is used when data is grouped, such as patients within hospitals. This takes into account the potential correlation of patients within the same group.\nNonlinear Regression: Nonlinear regression can be used when the relationship between the independent and dependent variables is not linear.\n\nRemember, selecting the appropriate regression model depends largely on the type of data at hand and the specific research question. We will be introducing the approach to univariable and multivariable linear and logistic regression analysis in R.\nBefore we start lets get some important packages loaded\n\n\nShow the solution\nrequired_packages <- c(\"tidyverse\", \"lubridate\", \"gtsummary\", \"broom\", \"performance\", \"see\", \"flextable\", \"stats\", \"car\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: gtsummary\n\nLoading required package: broom\n\nLoading required package: performance\n\nLoading required package: see\n\nLoading required package: flextable\n\n\nAttaching package: 'flextable'\n\n\nThe following objects are masked from 'package:gtsummary':\n\n    as_flextable, continuous_summary\n\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\n\nLoading required package: car\n\nLoading required package: carData\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nLets call in the data:\n\n\nShow the solution\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n#create a sequence of numbers to represent time\nc19_df <- c19_df %>%\n  arrange(date) %>%\n  group_by(date) %>%\n  mutate(date_index = cur_group_id(),\n         age_cat=ifelse(age<20, \"Less than 20\",\n                        ifelse(age %in% 20:40, \"20-40\",\n                               ifelse(age %in% 40:60, \"40-60\",\n                                      ifelse(age %in% 60:80, \"60:80\", \">80\"))))) %>%\n  ungroup()\n\n\nJust to be consistent we what I said yesterday- before diving into the data always always skim the data first to get a quick feels\n\n\nShow the solution\nc19_df %>% \n  skimr::skim()\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n37165\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n11\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate\n0\n1\n10\n10\n0\n1013\n0\n\n\ndate_announced\n0\n1\n10\n10\n0\n1009\n0\n\n\ndate_positive\n0\n1\n10\n10\n0\n1007\n0\n\n\ndate_dose1\n0\n1\n0\n10\n22440\n298\n0\n\n\ndate_dose2\n0\n1\n0\n10\n28038\n267\n0\n\n\ndate_dose3\n0\n1\n0\n10\n35724\n161\n0\n\n\nbrand1\n0\n1\n0\n16\n22440\n8\n0\n\n\nbrand2\n0\n1\n0\n16\n28038\n7\n0\n\n\nbrand3\n0\n1\n0\n16\n35724\n6\n0\n\n\nstate\n0\n1\n5\n17\n0\n16\n0\n\n\nage_cat\n0\n1\n3\n12\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n62.66\n16.59\n0\n51\n64\n75\n130\n▁▃▇▃▁\n\n\nmale\n0\n1\n0.58\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nbid\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nmalaysian\n0\n1\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\ncomorb\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\ndate_index\n0\n1\n419.28\n122.63\n1\n362\n393\n444\n1013\n▁▇▅▁▁\n\n\n\n\n\n\nLinear regression\nThe R function lm() perform linear regression, assessing the relationship between numeric response and explanatory variables that are assumed to have a linear relationship.\nProvide the equation as a formula, with the response and explanatory column names separated by a tilde ~. Also, specify the dataset to data =. Define the model results as an R object, to use later.\n\nUnivariate linear regression\n\n\nShow the solution\nlm_results <- lm(age ~ malaysian, data = c19_df)\n\n\nYou can then run summary() on the model results to see the coefficients (Estimates), P-value, residuals, and other measures.\n\n\nShow the solution\nsummary(lm_results)\n\n\n\nCall:\nlm(formula = age ~ malaysian, data = c19_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-64.264 -10.264   0.736  11.736  80.530 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  49.4699     0.2509  197.16   <2e-16 ***\nmalaysian    14.7944     0.2658   55.67   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.94 on 37163 degrees of freedom\nMultiple R-squared:  0.07697,   Adjusted R-squared:  0.07695 \nF-statistic:  3099 on 1 and 37163 DF,  p-value: < 2.2e-16\n\n\nAlternatively you can use the tidy() function from the broom package to pull the results in to a table. What the results tell us is that Malaysians (change from 0 to 1) the age of COVID-19 death increases by 14.8 years and this is statistically significant (p<0.01).\n\n\nShow the solution\ntidy(lm_results)\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)     49.5     0.251     197.        0\n2 malaysian       14.8     0.266      55.7       0\n\n\nYou can then also use this regression to add it to a ggplot, to do this we first pull the points for the observed data and the fitted line in to one data frame using the augment() function from broom.\n\n\nShow the solution\n## pull the regression points and observed data in to one dataset\npoints <- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = malaysian)) + \n  ## add points for height \n  geom_point(aes(y = age)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\nWhen using a categorical variable as the predictor as we did above the plots can appear somewhat difficult to understand. We can try using a continuous on continuous method and implement it more simpler directly in ggplot and it should look like:\n\n\nShow the solution\n## add your data to a plot \n ggplot(c19_df, aes(x = date_index, y = age)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nMultivariable linear regression\nThere is almost no difference when carrying out multivariable linear regression, instead we just add on the expression + to add more variables to the equation.\n\n\nShow the solution\nlm_results <- lm(age ~ malaysian + bid + male + state + comorb, \n                 data = c19_df)\n\n\nCheck the output\n\n\nShow the solution\ntidy(lm_results)\n\n\n# A tibble: 20 × 5\n   term                   estimate std.error statistic  p.value\n   <chr>                     <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)             47.6        0.380  125.     0       \n 2 malaysian               12.9        0.284   45.3    0       \n 3 bid                     -1.24       0.209   -5.94   2.95e- 9\n 4 male                    -1.42       0.165   -8.63   6.64e-18\n 5 stateKedah               1.48       0.376    3.95   7.94e- 5\n 6 stateKelantan            4.94       0.474   10.4    2.24e-25\n 7 stateMelaka              0.764      0.504    1.52   1.29e- 1\n 8 stateNegeri Sembilan     3.19       0.459    6.95   3.81e-12\n 9 statePahang              1.92       0.537    3.57   3.57e- 4\n10 statePerak               5.28       0.407   13.0    2.08e-38\n11 statePerlis              6.10       1.13     5.38   7.62e- 8\n12 statePulau Pinang        5.42       0.412   13.2    1.88e-39\n13 stateSabah               6.45       0.362   17.8    9.59e-71\n14 stateSarawak             6.06       0.436   13.9    5.95e-44\n15 stateSelangor            0.0176     0.274    0.0645 9.49e- 1\n16 stateTerengganu          3.05       0.569    5.35   8.61e- 8\n17 stateW.P. Kuala Lumpur   2.96       0.373    7.93   2.17e-15\n18 stateW.P. Labuan         0.246      1.26     0.194  8.46e- 1\n19 stateW.P. Putrajaya      2.96       2.92     1.01   3.10e- 1\n20 comorb                   3.00       0.210   14.3    4.53e-46\n\n\nPretty simple right!\n\n\nUnivariate logistic regression\nThe function glm() from the stats package (part of base R) is used to fit Generalized Linear Models (GLM). glm() can be used for univariate and multivariable logistic regression (e.g. to get Odds Ratios). Here are the core parts:\n\nformula = The model is provided to glm() as an equation, with the outcome on the left and explanatory variables on the right of a tilde ~.\nfamily = This determines the type of model to run. For logistic regression, use family = \"binomial\", for poisson use family = \"poisson\". Other examples are in the table below.\ndata = Specify your data frame\n\nIf necessary, you can also specify the link function via the syntax family = familytype(link = \"linkfunction\")). You can read more in the documentation about other families and optional arguments such as weights = and subset = (?glm).\n\n\n\nFamily\nDefault link function\n\n\n\n\n\"binomial\"\n(link = \"logit\")\n\n\n\"gaussian\"\n(link = \"identity\")\n\n\n\"Gamma\"\n(link = \"inverse\")\n\n\n\"inverse.gaussian\"\n(link = \"1/mu^2\")\n\n\n\"poisson\"\n(link = \"log\")\n\n\n\"quasi\"\n(link = \"identity\", variance = \"constant\")\n\n\n\"quasibinomial\"\n(link = \"logit\")\n\n\n\"quasipoisson\"\n(link = \"log\")\n\n\n\nWhen running glm() it is most common to save the results as a named R object. Then you can print the results to your console using summary() as shown below, or perform other operations on the results (e.g. exponentiate). If you need to run a negative binomial regression you can use the MASS package; the glm.nb() uses the same syntax as glm(). For a walk-through of different regressions, see the UCLA stats page. So lets try to run a logistic regression model first:\n\n\nShow the solution\nmodel <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df)\nsummary(model)\n\n\n\nCall:\nglm(formula = malaysian ~ age_cat, family = \"binomial\", data = c19_df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7226   0.2230   0.2746   0.6605   0.7780  \n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          3.68148    0.08588  42.868   <2e-16 ***\nage_cat20-40        -2.64145    0.09382 -28.156   <2e-16 ***\nage_cat40-60        -2.26993    0.08895 -25.519   <2e-16 ***\nage_cat60:80        -0.42253    0.09566  -4.417    1e-05 ***\nage_catLess than 20 -2.19987    0.18614 -11.818   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 25533  on 37164  degrees of freedom\nResidual deviance: 22416  on 37160  degrees of freedom\nAIC: 22426\n\nNumber of Fisher Scoring iterations: 6\n\n\nCan you spot a potential issue in the summary above?\n\n\nShow the solution\nc19_df %>% \n  mutate(age_cat = fct_relevel(age_cat, \"Less than 20\", after = 0)) %>% \n  glm(formula = malaysian ~ age_cat, family = \"binomial\") %>% \n  summary()\n\n\n\nCall:\nglm(formula = malaysian ~ age_cat, family = \"binomial\", data = .)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7226   0.2230   0.2746   0.6605   0.7780  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.48160    0.16514   8.972  < 2e-16 ***\nage_cat>80    2.19987    0.18614  11.818  < 2e-16 ***\nage_cat20-40 -0.44158    0.16941  -2.607  0.00914 ** \nage_cat40-60 -0.07006    0.16676  -0.420  0.67440    \nage_cat60:80  1.77735    0.17043  10.428  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 25533  on 37164  degrees of freedom\nResidual deviance: 22416  on 37160  degrees of freedom\nAIC: 22426\n\nNumber of Fisher Scoring iterations: 6\n\n\nLets clean that up so we have a nice exponentiated and round up the hyper precise output:\n\n\nShow the solution\nmodel <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nShow the solution\nmodel\n\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic p.value conf.low conf.high\n  <chr>                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)            39.7       0.09     42.9        0    33.7      47.2 \n2 age_cat20-40            0.07      0.09    -28.2        0     0.06      0.09\n3 age_cat40-60            0.1       0.09    -25.5        0     0.09      0.12\n4 age_cat60:80            0.66      0.1      -4.42       0     0.54      0.79\n5 age_catLess than 20     0.11      0.19    -11.8        0     0.08      0.16\n\n\n\n\nMultivariable logistic regression\nThe expressions utilised are exactly the same as in the multivariable linear regression model\n\n\nShow the solution\nlog_reg <- glm(malaysian ~ age_cat + bid + comorb + male + state, \n               family = \"binomial\", data = c19_df)\n\ntidy(log_reg, exponentiate = TRUE, conf.int = TRUE)\n\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic   p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n 1 (Intercept)          38.5       0.112      32.6  1.57e-232  31.0      48.1   \n 2 age_cat20-40          0.0708    0.101     -26.3  1.48e-152   0.0579    0.0859\n 3 age_cat40-60          0.106     0.0943    -23.8  7.00e-125   0.0880    0.127 \n 4 age_cat60:80          0.534     0.100      -6.27 3.66e- 10   0.438     0.648 \n 5 age_catLess than 20   0.142     0.205      -9.51 1.87e- 21   0.0954    0.214 \n 6 bid                   0.282     0.0398    -31.8  1.16e-221   0.261     0.305 \n 7 comorb                3.45      0.0396     31.3  2.45e-215   3.19      3.73  \n 8 male                  1.10      0.0394      2.31 2.12e-  2   1.01      1.18  \n 9 stateKedah            3.37      0.139       8.76 1.88e- 18   2.58      4.45  \n10 stateKelantan         2.75      0.194       5.22 1.76e-  7   1.91      4.09  \n# ℹ 13 more rows\n\n\nIf you want to include two variables and an interaction between them you can separate them with an asterisk * instead of a +. Separate them with a colon : if you are only specifying the interaction. For example:\n\n\nShow the solution\nlog_intrx_reg <- glm(malaysian ~ age_cat*bid + comorb + male + state, \n               family = \"binomial\", data = c19_df)\n\ntidy(log_reg, exponentiate = TRUE, conf.int = TRUE)\n\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic   p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n 1 (Intercept)          38.5       0.112      32.6  1.57e-232  31.0      48.1   \n 2 age_cat20-40          0.0708    0.101     -26.3  1.48e-152   0.0579    0.0859\n 3 age_cat40-60          0.106     0.0943    -23.8  7.00e-125   0.0880    0.127 \n 4 age_cat60:80          0.534     0.100      -6.27 3.66e- 10   0.438     0.648 \n 5 age_catLess than 20   0.142     0.205      -9.51 1.87e- 21   0.0954    0.214 \n 6 bid                   0.282     0.0398    -31.8  1.16e-221   0.261     0.305 \n 7 comorb                3.45      0.0396     31.3  2.45e-215   3.19      3.73  \n 8 male                  1.10      0.0394      2.31 2.12e-  2   1.01      1.18  \n 9 stateKedah            3.37      0.139       8.76 1.88e- 18   2.58      4.45  \n10 stateKelantan         2.75      0.194       5.22 1.76e-  7   1.91      4.09  \n# ℹ 13 more rows\n\n\n\n\n\nModel building\nYou can build your model step-by-step, saving various models that include certain explanatory variables. You can compare these models with likelihood-ratio tests using lrtest() from the package lmtest, as below:\n\n\nShow the solution\nmodel1 <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df)\nmodel2 <- glm(malaysian ~ age_cat + bid, family = \"binomial\", data = c19_df)\n\nlmtest::lrtest(model1, model2)\n\n\nLikelihood ratio test\n\nModel 1: malaysian ~ age_cat\nModel 2: malaysian ~ age_cat + bid\n  #Df LogLik Df Chisq Pr(>Chisq)    \n1   5 -11208                        \n2   6 -10376  1  1663  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf you prefer to instead leverage the computation available within you processor we can instead take the model object and apply the step() function from the stats package. Specify which variable selection direction you want use when building the model.\n\n\nShow the solution\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_log_reg <- log_reg %>%\n  step(direction = \"both\", trace = FALSE)\n\n\nCheck the best fitting models based on both a backward and forward method\n\n\nShow the solution\nlog_tab_base <- final_log_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round \n\n#check\nlog_tab_base\n\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 (Intercept)            38.5       0.11     32.6     0       31        48.1 \n 2 age_cat20-40            0.07      0.1     -26.3     0        0.06      0.09\n 3 age_cat40-60            0.11      0.09    -23.8     0        0.09      0.13\n 4 age_cat60:80            0.53      0.1      -6.27    0        0.44      0.65\n 5 age_catLess than 20     0.14      0.21     -9.51    0        0.1       0.21\n 6 bid                     0.28      0.04    -31.8     0        0.26      0.31\n 7 comorb                  3.45      0.04     31.3     0        3.19      3.73\n 8 male                    1.1       0.04      2.31    0.02     1.01      1.18\n 9 stateKedah              3.37      0.14      8.76    0        2.58      4.45\n10 stateKelantan           2.75      0.19      5.22    0        1.91      4.09\n# ℹ 13 more rows\n\n\n\n\ngtsummary() and regression\nMy favourite package again. The gtsummary package provides the tbl_regression() function, which will take the outputs from a regression (glm() in this case) and produce an nice summary table.\n\n\nShow the solution\n## show results table of final regression \nmv_tab <- tbl_regression(final_log_reg, exponentiate = TRUE)\n\n#check\nmv_tab\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    age_cat\n\n\n\n        >80\n—\n—\n\n        20-40\n0.07\n0.06, 0.09\n<0.001\n        40-60\n0.11\n0.09, 0.13\n<0.001\n        60:80\n0.53\n0.44, 0.65\n<0.001\n        Less than 20\n0.14\n0.10, 0.21\n<0.001\n    bid\n0.28\n0.26, 0.31\n<0.001\n    comorb\n3.45\n3.19, 3.73\n<0.001\n    male\n1.10\n1.01, 1.18\n0.021\n    state\n\n\n\n        Johor\n—\n—\n\n        Kedah\n3.37\n2.58, 4.45\n<0.001\n        Kelantan\n2.75\n1.91, 4.09\n<0.001\n        Melaka\n2.17\n1.58, 3.07\n<0.001\n        Negeri Sembilan\n1.30\n1.00, 1.71\n0.055\n        Pahang\n1.86\n1.33, 2.65\n<0.001\n        Perak\n2.85\n2.11, 3.92\n<0.001\n        Perlis\n2.75\n1.10, 9.25\n0.057\n        Pulau Pinang\n0.81\n0.66, 1.00\n0.044\n        Sabah\n0.26\n0.23, 0.31\n<0.001\n        Sarawak\n4.49\n2.96, 7.15\n<0.001\n        Selangor\n0.47\n0.41, 0.54\n<0.001\n        Terengganu\n3.16\n1.96, 5.44\n<0.001\n        W.P. Kuala Lumpur\n0.40\n0.34, 0.47\n<0.001\n        W.P. Labuan\n0.44\n0.28, 0.72\n<0.001\n        W.P. Putrajaya\n34,817\n340, 10,225,778,102,203,496\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nIts so good! But it doesn’t end there. tbl_uvregression() from the gtsummary package produces a table of univariate regression results. We select only the necessary columns from the linelist (explanatory variables and the outcome variable) and pipe them into tbl_uvregression(). We are going to run univariate regression on each of the columns we defined as explanatory_vars in the data\nWithin the function itself, we provide the method = as glm (no quotes), the y = outcome column (outcome), specify to method.args = that we want to run logistic regression via family = binomial, and we tell it to exponentiate the results.\nThe output is HTML and contains the counts\n\n\nShow the solution\n## define variables of interest \nexplanatory_vars <- c(\"bid\", \"male\", \"comorb\", \"age_cat\", \"state\")#lets leave state ut to increase the computation\n\n#cteate a data subset and run the regression\nuniv_tab <- c19_df %>% \n  dplyr::select(explanatory_vars, malaysian) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = malaysian,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    bid\n37,165\n0.20\n0.19, 0.22\n<0.001\n    male\n37,165\n0.93\n0.87, 0.99\n0.030\n    comorb\n37,165\n5.61\n5.24, 6.00\n<0.001\n    age_cat\n37,165\n\n\n\n        >80\n\n—\n—\n\n        20-40\n\n0.07\n0.06, 0.09\n<0.001\n        40-60\n\n0.10\n0.09, 0.12\n<0.001\n        60:80\n\n0.66\n0.54, 0.79\n<0.001\n        Less than 20\n\n0.11\n0.08, 0.16\n<0.001\n    state\n37,165\n\n\n\n        Johor\n\n—\n—\n\n        Kedah\n\n3.21\n2.49, 4.20\n<0.001\n        Kelantan\n\n3.65\n2.57, 5.37\n<0.001\n        Melaka\n\n2.18\n1.60, 3.02\n<0.001\n        Negeri Sembilan\n\n1.51\n1.19, 1.95\n0.001\n        Pahang\n\n1.98\n1.45, 2.79\n<0.001\n        Perak\n\n3.40\n2.56, 4.62\n<0.001\n        Perlis\n\n4.08\n1.72, 13.3\n0.006\n        Pulau Pinang\n\n0.85\n0.71, 1.03\n0.094\n        Sabah\n\n0.34\n0.29, 0.38\n<0.001\n        Sarawak\n\n6.45\n4.32, 10.1\n<0.001\n        Selangor\n\n0.41\n0.36, 0.46\n<0.001\n        Terengganu\n\n4.37\n2.76, 7.42\n<0.001\n        W.P. Kuala Lumpur\n\n0.33\n0.29, 0.38\n<0.001\n        W.P. Labuan\n\n0.39\n0.26, 0.61\n<0.001\n        W.P. Putrajaya\n\n65,188\n434, 166,945,178,905,595,744\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nNow for some magic\n\n\nShow the solution\n## combine with univariate results \nmv_merge <- tbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names\n\n#check\nmv_merge\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      \n        Univariate\n      \n      \n        Multivariable\n      \n    \n    \n      N\n      OR1\n      95% CI1\n      p-value\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    bid\n37,165\n0.20\n0.19, 0.22\n<0.001\n0.28\n0.26, 0.31\n<0.001\n    male\n37,165\n0.93\n0.87, 0.99\n0.030\n1.10\n1.01, 1.18\n0.021\n    comorb\n37,165\n5.61\n5.24, 6.00\n<0.001\n3.45\n3.19, 3.73\n<0.001\n    age_cat\n37,165\n\n\n\n\n\n\n        >80\n\n—\n—\n\n—\n—\n\n        20-40\n\n0.07\n0.06, 0.09\n<0.001\n0.07\n0.06, 0.09\n<0.001\n        40-60\n\n0.10\n0.09, 0.12\n<0.001\n0.11\n0.09, 0.13\n<0.001\n        60:80\n\n0.66\n0.54, 0.79\n<0.001\n0.53\n0.44, 0.65\n<0.001\n        Less than 20\n\n0.11\n0.08, 0.16\n<0.001\n0.14\n0.10, 0.21\n<0.001\n    state\n37,165\n\n\n\n\n\n\n        Johor\n\n—\n—\n\n—\n—\n\n        Kedah\n\n3.21\n2.49, 4.20\n<0.001\n3.37\n2.58, 4.45\n<0.001\n        Kelantan\n\n3.65\n2.57, 5.37\n<0.001\n2.75\n1.91, 4.09\n<0.001\n        Melaka\n\n2.18\n1.60, 3.02\n<0.001\n2.17\n1.58, 3.07\n<0.001\n        Negeri Sembilan\n\n1.51\n1.19, 1.95\n0.001\n1.30\n1.00, 1.71\n0.055\n        Pahang\n\n1.98\n1.45, 2.79\n<0.001\n1.86\n1.33, 2.65\n<0.001\n        Perak\n\n3.40\n2.56, 4.62\n<0.001\n2.85\n2.11, 3.92\n<0.001\n        Perlis\n\n4.08\n1.72, 13.3\n0.006\n2.75\n1.10, 9.25\n0.057\n        Pulau Pinang\n\n0.85\n0.71, 1.03\n0.094\n0.81\n0.66, 1.00\n0.044\n        Sabah\n\n0.34\n0.29, 0.38\n<0.001\n0.26\n0.23, 0.31\n<0.001\n        Sarawak\n\n6.45\n4.32, 10.1\n<0.001\n4.49\n2.96, 7.15\n<0.001\n        Selangor\n\n0.41\n0.36, 0.46\n<0.001\n0.47\n0.41, 0.54\n<0.001\n        Terengganu\n\n4.37\n2.76, 7.42\n<0.001\n3.16\n1.96, 5.44\n<0.001\n        W.P. Kuala Lumpur\n\n0.33\n0.29, 0.38\n<0.001\n0.40\n0.34, 0.47\n<0.001\n        W.P. Labuan\n\n0.39\n0.26, 0.61\n<0.001\n0.44\n0.28, 0.72\n<0.001\n        W.P. Putrajaya\n\n65,188\n434, 166,945,178,905,595,744\n>0.9\n34,817\n340, 10,225,778,102,203,496\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nOne final piece of magic! We can export our publication ready regression table into a document. Lovely!\n\n\nShow the solution\nmv_merge %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\n\n\nModel evaluation in r using the performance() and car()\nLets just run through quickly how we can evaluate linear and logistics models in R.\n\nLinear model evaluation\nLinearity and Homoscedasticity: These can be checked using a residuals vs fitted values plot.\nFor linearity, we expect to see no pattern or curve in the points, while for homoscedasticity, we expect the spread of residuals to be approximately constant across all levels of the independent variables.\n\n\nShow the solution\ncheck_model(lm_results)\n\n\nNormality of residuals: This can be checked using a QQ plot.\nIf the residuals are normally distributed, the points in the QQ plot will generally follow the straight line.\n\n\nShow the solution\ncheck_normality(model)\n\n\nIndependence of residuals (No autocorrelation): This can be checked using the Durbin-Watson test.\nIf the test statistic is approximately 2, it indicates no autocorrelation.\n\n\nShow the solution\ncheck_autocorrelation(model)\n\n\nNo multicollinearity: This can be checked using Variance Inflation Factor (VIF).\nA VIF value greater than 5 (some suggest 10) might indicate problematic multicollinearity.\n\n\nShow the solution\ncheck_collinearity(model)\n\n\n\n\nLogistic model evaluation\nBinary Outcome: Logistic regression requires the dependent variable to be binary or ordinal in ordinal logistic regression.\nObservation Independence: Observations should be independent of each other. This is more of a study design issue than something you would check with a statistical test.\nNo Multicollinearity: Just like in linear regression, the independent variables should not be highly correlated with each other.\nJust like in linear regression, a rule of thumb is that if the VIF is greater than 5 (or sometimes 10), then the multicollinearity is high.\n\n\nShow the solution\n# Checking for Multicollinearity:\ncheck_collinearity(mv_model)\n\n\nLinearity of Log Odds: While logistic regression does not assume linearity of the relationship between the independent variables and the dependent variable, it does assume linearity of independent variables and the log odds.\nChecking for Linearity of Log Odds:\nLogistic regression assumes that the log odds of the outcome is a linear combination of the independent variables. This is a complex assumption to check, but one approach is to look for significant interactions between your predictors and the log odds.\nFirst, fit a model that allows for the possibility of a non-linear relationship:\n\n\nShow the solution\nlogit_model_2 <- glm(outcome ~ predictor + I(predictor^2), family=binomial, data=df)\n\n\nThen compare this model with your original model:\n\n\nShow the solution\nanova(logit_model, logit_model_2, test=\"Chisq\")\n\n\nIf the model with the quadratic term is significantly better than the model without (i.e., p < 0.05), this could be a sign that the assumption of linearity of the log odds has been violated.\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook"
  },
  {
    "objectID": "regression_tutorial.html",
    "href": "regression_tutorial.html",
    "title": "Regression- Tutorial",
    "section": "",
    "text": "Task 1: Univariate Linear Regression\nQuestion: Perform a univariate linear regression to predict “age” using the “male” variable.\nSteps:\n\nInstall and load the required packages: tidyverse and broom.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nFit a univariate linear regression model using the lm() function.\nSummarise the model using tidy() from the broom package.\n\n\n\nShow the solution\n# Step 1\n#install.packages(c(\"tidyverse\", \"broom\"))\nlibrary(tidyverse)\nlibrary(broom)\n\n# Step 2\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 3\nmodel <- lm(age ~ male, data = c19_df)\n\n# Step 4\ntidy(model)\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    63.6      0.132    482.   0       \n2 male           -1.60     0.174     -9.18 4.71e-20\n\n\n\n\nTask 2: Multivariate Linear Regression\nQuestion: Perform a multivariate linear regression to predict “age” using the “male” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate linear regression model using the lm() function.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nShow the solution\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- lm(age ~ male + malaysian, data = c19_df)\n\n# Step 3\nmodel %>% \n  tbl_regression() %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\n\nTask 3: Univariate Logistic Regression\nQuestion: Perform a univariate logistic regression to predict “male” (binarize to 0 and 1) using the “age” variable.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a univariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using tidy().\n\n\n\nShow the solution\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 2\nmodel <- glm(male ~ age, data = c19_df, family = \"binomial\")\n\n# Step 3\ntidy(model)\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.669    0.0414       16.2  1.11e-58\n2 age         -0.00583  0.000636     -9.16 5.40e-20\n\n\n\n\nTask 4: Multivariate Logistic Regression\nQuestion: Perform a multivariate logistic regression to predict “male” using the “age” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nShow the solution\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- glm(male ~ age + malaysian, data = c19_df, family = \"binomial\")\n\n# Step 3\nmodel %>%\n  tbl_regression(exponentiate = TRUE) %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\n\nTask 5: Model Evaluation\nQuestion: Evaluate the logistic regression model from Task 4 using AUC-ROC.\nSteps:\n\nInstall and load the pROC package (Note: Upon up the documentation to figure out the nuts and bolts.)\nUse the predict() function to get the predicted probabilities from the logistic regression model.\nUse the roc() function to compute the AUC-ROC.\n\n\n\nShow the solution\n# Step 1\n#install.packages(\"pROC\")\nlibrary(pROC)\n\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\nShow the solution\n# Step 2\nprobabilities <- predict(model, type = \"response\")\n\n# Step 3\nroc_obj <- roc(c19_df$male, probabilities)\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nShow the solution\n# Display AUC\nauc(roc_obj)\n\n\nArea under the curve: 0.5289"
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "Data Visualisation in R- Tutorial",
    "section": "",
    "text": "Can anyone guess what statistical phenomenon is being observed here?\n\n\nShow the solution\ndatasaurus_dozen %>% group_by(dataset) %>%\n  summarize( mean(x), mean(y), var(x), var(y), cor(x,y)) %>%\n  kable(digits=3) %>% kable_styling(bootstrap_options = c(\"striped\"), font_size=17)\n\n\n\n\n \n  \n    dataset \n    mean(x) \n    mean(y) \n    var(x) \n    var(y) \n    cor(x, y) \n  \n \n\n  \n    away \n    54.266 \n    47.835 \n    281.227 \n    725.750 \n    -0.064 \n  \n  \n    bullseye \n    54.269 \n    47.831 \n    281.207 \n    725.533 \n    -0.069 \n  \n  \n    circle \n    54.267 \n    47.838 \n    280.898 \n    725.227 \n    -0.068 \n  \n  \n    dino \n    54.263 \n    47.832 \n    281.070 \n    725.516 \n    -0.064 \n  \n  \n    dots \n    54.260 \n    47.840 \n    281.157 \n    725.235 \n    -0.060 \n  \n  \n    h_lines \n    54.261 \n    47.830 \n    281.095 \n    725.757 \n    -0.062 \n  \n  \n    high_lines \n    54.269 \n    47.835 \n    281.122 \n    725.763 \n    -0.069 \n  \n  \n    slant_down \n    54.268 \n    47.836 \n    281.124 \n    725.554 \n    -0.069 \n  \n  \n    slant_up \n    54.266 \n    47.831 \n    281.194 \n    725.689 \n    -0.069 \n  \n  \n    star \n    54.267 \n    47.840 \n    281.198 \n    725.240 \n    -0.063 \n  \n  \n    v_lines \n    54.270 \n    47.837 \n    281.232 \n    725.639 \n    -0.069 \n  \n  \n    wide_lines \n    54.267 \n    47.832 \n    281.233 \n    725.651 \n    -0.067 \n  \n  \n    x_shape \n    54.260 \n    47.840 \n    281.231 \n    725.225 \n    -0.066 \n  \n\n\n\n\n\nVisualisation in key in understanding the underlying data and in key in telling a story.\n\n\n\n\n\n\nDanger\n\n\n\n\nPosition is the most powerful way to demonstrate differences\nPie charts/ 3D charts are bad\nAlways design a visualization with a question in mind\n\n\n\nggplot2 holds the title of the most commonly used data visualization package in R. Its central function, ggplot(), forms the backbone of this package. The package, including its resulting figures, are often casually referred to as “ggplot” and the figures it produces as “ggplots”. The prefix “gg” stands for the “grammar of graphics”, which underpins the structure of the images generated. A host of additional R packages exists to expand the capabilities of ggplot2.\nIn contrast to the base R plotting syntax, ggplot2 introduces a unique syntax that might pose a learning challenge initially. It usually demands data to be organized in a way that aligns well with the tidyverse, making these packages effective when used together.\nOver the next 2 hours we’ll walk through the basics of plotting with ggplot2.\n\n\n\n\n\n\nTip\n\n\n\nThis session will be a primer. Head on to this great resources to learn more:\n\nThere are several great tips on the R Epi Handbook\nCheat sheets are hacks. The invaluable ggplot data visualization cheat sheet can be downloaded from the RStudio website.\nFor those seeking innovative ideas for data visualization, we recommend exploring websites such as the R graph gallery and Data-to-viz."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the Ready for R! Worksho organised by the Research Training Unit, Faculty of Medicine, University Malaya\n\n\nThis workshop lays the groundwork for addressing key practical aspects of programming and other essential computer skills needed for both research and implementation of statistical methods. The course offers an introduction to programming in R and the tidyverse, guidance on coding best practices, a primer on data visualization and data wrangling, as well as an exploration of both descriptive and inferential statistics using R. Additionally, the workshop also introduces the concept of regression analysis in R."
  },
  {
    "objectID": "data_wranggling_tutorial.html",
    "href": "data_wranggling_tutorial.html",
    "title": "Data Wrangling in R- Tutorial",
    "section": "",
    "text": "Task 1: Calculate the average age for deaths by state and find the state with the highest average age.\nSteps:\n\nFirst, we need to group the data by state.\nThen, we can summarize the average age per state using summarise.\nUse arrange to sort the average age in descending order to find the state with the highest average age.\n\nSolution:\n\n\nShow the solution\nc19_df %>% \n  group_by(state) %>%\n  summarise(avg_age = mean(age, na.rm = TRUE)) %>%\n  arrange(desc(avg_age))\n\n\n\n\nTask 2: Determine the proportion of male to female deaths in each state.\nSteps:\n\nUsing mutate, create a new column called gender using ifelse to convert the male column to ‘Male’ and ‘Female’.\nGroup the data by state and gender.\nSummarise the count of each gender in each state.\nCreate a new column with the proportion of each gender in each state.\n\nSolution:\n\n\nShow the solution\nc19_df %>%\n  mutate(gender = ifelse(male == 1, \"Male\", \"Female\")) %>%\n  group_by(state, gender) %>%\n  summarise(count = n()) %>%\n  mutate(proportion = count / sum(count))\n\n\n\n\nTask 3: Determine the total number of deaths by month and year.\nSteps:\n\nConvert the date column to Date type if it’s not already.\nUse mutate to create new columns year and month using the year and month functions from the lubridate package.\nGroup the data by year and month.\nUse summarise to count the number of deaths.\n\nSolution:\n\n\nShow the solution\nc19_df %>%\n  mutate(date = as.Date(date),\n         year = year(date),\n         month = month(date)) %>%\n  group_by(year, month) %>%\n  summarise(deaths = n())\n\n\n\n\nTask 4: Determine if comorbidities are more common in Malaysian or non-Malaysian deaths.\nSteps:\n\nCreate a new column nationality that categorizes malaysian into ‘Malaysian’ and ‘Non-Malaysian’ using mutate and ifelse.\nGroup by nationality.\nSummarise the average comorbidity rate (comorb).\n\nSolution:\n\n\nShow the solution\nc19_df %>%\n  mutate(nationality = ifelse(malaysian == 1, \"Malaysian\", \"Non-Malaysian\")) %>%\n  group_by(nationality) %>%\n  summarise(avg_comorb = mean(comorb, na.rm = TRUE))\n\n\n\n\nTask 5: Find out the most common vaccine brand combination that was administered.\nSteps:\n\nUse mutate to create a new column brands_combo that concatenates brand1, brand2, and brand3.\nfilter to keep only those rows where brands_combo is not empty.\nGroup by brands_combo.\nCount the number of occurrences for each vaccine brand combination using summarise.\n\nSolution:\n\n\nShow the solution\nc19_df %>%\n  unite(col=\"profile\", \n        brand1:brand3, \n        sep=\"_\")  %>%\n  filter(profile != \"--\") %>%\n  group_by(profile) %>%\n  summarise(count = n()) %>%\n  arrange(desc(count))"
  },
  {
    "objectID": "descriptives.html",
    "href": "descriptives.html",
    "title": "Descriptive Statistics",
    "section": "",
    "text": "Descriptive statistics form the bedrock of any complex analysis. Descriptive statistics summarize raw data and provide a snapshot of the sample’s features, revealing trends, patterns, and distributions, essential for making the data comprehensible. They provide an initial understanding of data, and an informed context for the application of more complex statistical or machine learning techniques.\n\n\n\n\n\nAs we mentioned in the Introduction- there are many ways to skin a cat in R.\n\ntidyverse() for Describing data\nAs we learned yesterday- the tidyverse has revolutionised data wrangling and can be extended likewise into the realm of descriptive statistics. Creating tables with dplyr functions summarise() and count() is a useful approach to calculating summary statistics, summarize by group, or pass tables to ggplot() or flextable(). In yesterdays tutorial we briefly did visit this, but we will extend on this in the next 10 minutes or so before transitioning into a simpler more efficient way of describing data in R.\nLets get some important packages loaded\n\n\nShow the solution\nrequired_packages <- c(\"tidyverse\", \"lubridate\", \"gtsummary\", \"rstatix\", \"janitor\", \"corrr\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: gtsummary\n\n#StandWithUkraine\n\nLoading required package: rstatix\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nLoading required package: janitor\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nLoading required package: corrr\n\n\n\nImporting some data\nLets call in the data:\n\n\nShow the solution\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n\nJust to be consistent we what I said yesterday- before diving into the data always always skim the data first to get a quick feels\n\n\nShow the solution\nc19_df %>% \n  skimr::skim()\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n37165\n\n\nNumber of columns\n15\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate\n0\n1\n10\n10\n0\n1013\n0\n\n\ndate_announced\n0\n1\n10\n10\n0\n1009\n0\n\n\ndate_positive\n0\n1\n10\n10\n0\n1007\n0\n\n\ndate_dose1\n0\n1\n0\n10\n22440\n298\n0\n\n\ndate_dose2\n0\n1\n0\n10\n28038\n267\n0\n\n\ndate_dose3\n0\n1\n0\n10\n35724\n161\n0\n\n\nbrand1\n0\n1\n0\n16\n22440\n8\n0\n\n\nbrand2\n0\n1\n0\n16\n28038\n7\n0\n\n\nbrand3\n0\n1\n0\n16\n35724\n6\n0\n\n\nstate\n0\n1\n5\n17\n0\n16\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n62.66\n16.59\n0\n51\n64\n75\n130\n▁▃▇▃▁\n\n\nmale\n0\n1\n0.58\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nbid\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nmalaysian\n0\n1\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\ncomorb\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\n\n\n\n\n\nGet counts\nThe most simple function to apply within summarise() is n(). Leave the parentheses empty to count the number of rows. You may have seen this being used several times yesterday. Let\n\n\nShow the solution\nc19_df %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows\n\n\n  n_rows\n1  37165\n\n\nLets try and stratify that by nationality and BID status:\n\n\nShow the solution\nc19_df %>% \n  group_by(malaysian, bid) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*\n\n\n`summarise()` has grouped output by 'malaysian'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   malaysian [2]\n  malaysian   bid n_rows\n      <int> <int>  <int>\n1         0     0   1958\n2         0     1   2077\n3         1     0  27297\n4         1     1   5833\n\n\nThe above command can be shortened by using the count() function instead. count() does the following:\n\nGroups the data by the columns provided to it\nSummarises them with n() (creating column n)\nUn-groups the data\n\n\n\nShow the solution\nc19_df %>%\n  count(malaysian, bid)\n\n\n  malaysian bid     n\n1         0   0  1958\n2         0   1  2077\n3         1   0 27297\n4         1   1  5833\n\n\n\n\nProportions\nProportions can be added by piping the table to mutate() to create a new column. Define the new column as the counts column (n by default) divided by the sum() of the counts column (this will return a proportion).\n\n\nShow the solution\nbid_summary <- c19_df %>% \n  count(malaysian, bid) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = round((n / sum(n))*100,2)) \n\n# print\nbid_summary\n\n\n  malaysian bid     n percent\n1         0   0  1958    5.27\n2         0   1  2077    5.59\n3         1   0 27297   73.45\n4         1   1  5833   15.69\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsing these structure we can very easily modify these summary statistics using ggplot() or html tables kable() or presentation ready tables using flextable() (flextable is not covered in this course but you can check it out here). An example of a plot is as follows:\n\n\nShow the solution\nc19_df %>% \n  count(malaysian, bid) %>%                     \n  mutate(percent = round((n / sum(n))*100,2)) %>%     \n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = malaysian,            # map outcome to x-axis\n        fill = bid,               # map age_cat to the fill\n        y = percent))             # map the counts column `n` to the height\n\n\n\n\n\nOr a nice little table summary:\n\n\nShow the solution\nc19_df %>% \n  count(malaysian, bid) %>%\n  mutate(malaysian = factor(malaysian,\n                               levels=c(\"0\",\"1\"),\n                               labels=c(\"non-Malaysian\", \"Malaysian\")),\n         bid = factor(bid,\n                               levels=c(\"0\",\"1\"),\n                               labels=c(\"Hospital\", \"BID\")),) %>%\n  mutate(percent = round((n / sum(n))*100,2))%>%\n  knitr::kable(format=\"html\", caption = \"COVID-19 fatalities by Nationality and Place of Death\",) %>% kableExtra::kable_minimal()\n\n\n\n\nCOVID-19 fatalities by Nationality and Place of Death\n \n  \n    malaysian \n    bid \n    n \n    percent \n  \n \n\n  \n    non-Malaysian \n    Hospital \n    1958 \n    5.27 \n  \n  \n    non-Malaysian \n    BID \n    2077 \n    5.59 \n  \n  \n    Malaysian \n    Hospital \n    27297 \n    73.45 \n  \n  \n    Malaysian \n    BID \n    5833 \n    15.69 \n  \n\n\n\n\n\n\n\n\n\nSummary statistics\nOne major advantage of dplyr and summarise() is the ability to return more advanced statistical summaries like median(), mean(), max(), min(), sd() (standard deviation), and percentiles. You can also use sum() to return the number of rows that meet certain logical criteria. As above, these outputs can be produced for the whole data frame set, or by group.\nThe syntax is the same - within the summarise() parentheses you provide the names of each new summary column followed by an equals sign and a statistical function to apply. Within the statistical function, give the column(s) to be operated on and any relevant arguments (e.g. na.rm = TRUE for most mathematical functions).\nYou can also use sum() to return the number of rows that meet a logical criteria. The expression within is counted if it evaluates to TRUE. For example:\n\nsum(age_years < 18, na.rm=T)\n\nsum(gender == \"male\", na.rm=T)\n\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\nBelow, c19_df data are summarised to describe the days delay from death to announcement (column days_death_state), by state.\n\n\nShow the solution\nc19_df %>%                 # begin with linelist, save out as new object\n  group_by(state) %>%      # group all calculations by hospital\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_death_state=date_announced-date) %>% # calculate the delay for each death\n  summarise(                                                         # only the below summary columns will be returned\n    deaths       = n(),                                                # number of rows per group\n    delay_max   = max(days_death_state, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_death_state, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_death_state, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_death_state >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / deaths)                    # convert previously-defined delay column to percent (scales gives the % sign behind)\n  )\n\n\n# A tibble: 16 × 7\n   state             deaths delay_max delay_mean delay_sd delay_3 pct_delay_3\n   <chr>              <int> <drtn>    <drtn>        <dbl>   <int> <chr>      \n 1 Johor               4741 253 days   4.8 days      12      1988 42%        \n 2 Kedah               2756 338 days  10.0 days      18.6    1531 56%        \n 3 Kelantan            1428 153 days   7.5 days      12.5     920 64%        \n 4 Melaka              1215 386 days   5.2 days      15       462 38%        \n 5 Negeri Sembilan     1546 274 days   8.7 days      19.5     659 43%        \n 6 Pahang              1037 325 days   5.2 days      19       392 38%        \n 7 Perak               2168 178 days   4.0 days       9.4    1031 48%        \n 8 Perlis               199  16 days   2.5 days       2.4      67 34%        \n 9 Pulau Pinang        2085 396 days   3.7 days      10.9     958 46%        \n10 Sabah               3212 237 days   4.9 days       8.7    2063 64%        \n11 Sarawak             1796 167 days   4.6 days       9.7     901 50%        \n12 Selangor           11028 370 days  17.5 days      23.5    8692 79%        \n13 Terengganu           905 150 days   3.2 days       7       421 47%        \n14 W.P. Kuala Lumpur   2861 315 days  11.0 days      21.3    2026 71%        \n15 W.P. Labuan          159  14 days   1.3 days       1.3      13 8%         \n16 W.P. Putrajaya        29 388 days  20.9 days      71.6      14 48%        \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nUse sum() with a logic statement to “count” rows that meet certain criteria (==)\n\nNote the use of na.rm = TRUE within mathematical functions like sum(), otherwise NA will be returned if there are any missing values\n\nUse the function percent() from the scales package to easily convert to percents\n\nSet accuracy = to 0.1 or 0.01 to ensure 1 or 2 decimal places respectively\n\n\nUse round() from base R to specify decimals\n\nTo calculate these statistics on the entire dataset, use summarise() without group_by()\n\nYou may create columns for the purposes of later calculations (e.g. denominators) that you eventually drop from your data frame with select().\n\n\n\n\n\nConditional statistics\nYou may want to return conditional statistics - e.g. the maximum of rows that meet certain criteria. This can be done by subsetting the column with brackets [ ].\n\n\nShow the solution\nc19_df %>% \n  group_by(state) %>% \n  summarise(\n    max_age_msian = median(age[malaysian == \"1\"], na.rm = T),\n    max_age_non_msian = median(age[malaysian == \"0\"], na.rm = T)\n  )\n\n\n# A tibble: 16 × 3\n   state             max_age_msian max_age_non_msian\n   <chr>                     <dbl>             <dbl>\n 1 Johor                      64                  45\n 2 Kedah                      65                  45\n 3 Kelantan                   68                  58\n 4 Melaka                     64                  42\n 5 Negeri Sembilan            67                  45\n 6 Pahang                     65                  46\n 7 Perak                      70                  46\n 8 Perlis                     71                  44\n 9 Pulau Pinang               70                  45\n10 Sabah                      69                  59\n11 Sarawak                    71                  42\n12 Selangor                   63                  47\n13 Terengganu                 67.5                50\n14 W.P. Kuala Lumpur          66                  47\n15 W.P. Labuan                61                  56\n16 W.P. Putrajaya             68                  NA\n\n\n\n\nPercentiles\nPercentiles and quantiles in dplyr deserve a special mention. To return quantiles, use quantile() with the defaults or specify the value(s) you would like with probs =.\n\n\nShow the solution\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nc19_df %>% \n  summarise(age_percentiles = quantile(age, na.rm = TRUE))\n\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2              51\n3              64\n4              75\n5             130\n\n\nOr manually defined percentiles that are grouped\n\n\nShow the solution\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nc19_df %>% \n  group_by(malaysian) %>%\n  summarise(\n    age_percentiles = quantile(\n      age,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    ) \n\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'malaysian'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 2\n# Groups:   malaysian [2]\n  malaysian age_percentiles\n      <int>           <dbl>\n1         0              30\n2         0              48\n3         0              56\n4         0              86\n5         1              35\n6         1              66\n7         1              76\n8         1              92\n\n\n\n\n\n\n\n\nTip\n\n\n\nDo keep in mind that there any many ways to skin the cat! And always there will be more efficient ways to do things as you progress through R- Here is an example from the rstatix package\n\n\nShow the solution\nc19_df %>% \n  group_by(malaysian) %>%\n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n\n# A tibble: 2 × 8\n  malaysian variable     n  `0%` `25%` `50%` `75%` `100%`\n      <int> <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n1         0 age       4035     0    41    48    56    130\n2         1 age      33130     0    54    66    76    110\n\n\n\n\n\n\nacross() multiple columns\nYou can use summarise() across multiple columns using across(). This makes life easier when you want to calculate the same statistics for many columns. Place across() within summarise() and specify the following:\n\n.cols = as either a vector of column names c() or “tidyselect” helper functions (explained below)\n\n.fns = the function to perform (no parentheses) - you can provide multiple within a list()\n\n\n\nShow the solution\nc19_df %>% \n  group_by(state) %>% \n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_toAnnounce_state=date_announced-date,\n         day_toDeath_state=date-date_positive) %>%\n  summarise(across(.cols = c(day_toDeath_state, days_toAnnounce_state), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments\n\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `state = \"Johor\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 16 × 5\n   state      day_toDeath_state_mean day_toDeath_state_sd days_toAnnounce_stat…¹\n   <chr>      <drtn>                                <dbl> <drtn>                \n 1 Johor      5.564016 days                          9.17  4.826408 days        \n 2 Kedah      6.058418 days                          6.43  9.989115 days        \n 3 Kelantan   5.427871 days                          6.74  7.468487 days        \n 4 Melaka     7.680658 days                          9.28  5.209053 days        \n 5 Negeri Se… 6.683700 days                          6.99  8.657827 days        \n 6 Pahang     7.459016 days                         13.1   5.176471 days        \n 7 Perak      4.484317 days                          7.59  3.975554 days        \n 8 Perlis     6.015075 days                         10.0   2.457286 days        \n 9 Pulau Pin… 4.852278 days                          4.75  3.738129 days        \n10 Sabah      5.929016 days                         15.8   4.892590 days        \n11 Sarawak    5.972717 days                          9.04  4.566258 days        \n12 Selangor   7.434168 days                         12.1  17.518680 days        \n13 Terengganu 5.896133 days                          6.78  3.240884 days        \n14 W.P. Kual… 6.166375 days                         12.1  11.021671 days        \n15 W.P. Labu… 6.232704 days                          6.47  1.314465 days        \n16 W.P. Putr… 7.862069 days                          7.29 20.896552 days        \n# ℹ abbreviated name: ¹​days_toAnnounce_state_mean\n# ℹ 1 more variable: days_toAnnounce_state_sd <dbl>\n\n\nHere are those “tidyselect” helper functions you can provide to .cols = to select columns:\n\neverything() - all other columns not mentioned\n\nlast_col() - the last column\n\nwhere() - applies a function to all columns and selects those which are TRUE\n\nstarts_with() - matches to a specified prefix. Example: starts_with(\"date\")\nends_with() - matches to a specified suffix. Example: ends_with(\"_end\")\n\ncontains() - columns containing a character string. Example: contains(\"time\")\nmatches() - to apply a regular expression (regex). Example: contains(\"[pt]al\")\n\nnum_range() -\nany_of() - matches if column is named. Useful if the name might not exist. Example: any_of(date_onset, date_death, cardiac_arrest)\n\n\n\nShow the solution\nc19_df %>% \n  group_by(state) %>%\n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))\n\n\n# A tibble: 16 × 6\n   state               age  male   bid malaysian comorb\n   <chr>             <dbl> <dbl> <dbl>     <dbl>  <dbl>\n 1 Johor              60.9 0.558 0.150     0.923  0.802\n 2 Kedah              63.1 0.536 0.191     0.975  0.812\n 3 Kelantan           66.7 0.505 0.233     0.978  0.852\n 4 Melaka             62.2 0.563 0.167     0.963  0.823\n 5 Negeri Sembilan    64.5 0.563 0.133     0.948  0.829\n 6 Pahang             63.2 0.606 0.149     0.959  0.808\n 7 Perak              67.0 0.577 0.187     0.976  0.859\n 8 Perlis             68.1 0.568 0.121     0.980  0.915\n 9 Pulau Pinang       66.0 0.584 0.227     0.911  0.791\n10 Sabah              65.4 0.601 0.379     0.800  0.800\n11 Sarawak            68.1 0.581 0.199     0.987  0.930\n12 Selangor           59.4 0.592 0.216     0.830  0.740\n13 Terengganu         64.9 0.534 0.145     0.981  0.871\n14 W.P. Kuala Lumpur  61.7 0.585 0.256     0.799  0.659\n15 W.P. Labuan        59.3 0.591 0.277     0.824  0.686\n16 W.P. Putrajaya     64.7 0.690 0.103     1      0.793\n\n\n\n\n\ngtsummary() package\nDescriptives statistics approaches in R are numerous.\nI initially heavily utilised dplyr and the janitor (you can find a tutorial here) and tableone (you can find a tutorial here) packages which are both fantastic packages. More recently however, I discovered gtsummary. And lets just say its the bomb! Its my absolutely favourite package for descriptive analysis (and we will explore some of its other powerful extensions later).\n\nIf you want to print your summary statistics in a pretty, publication-ready graphic, you can use the gtsummary package and its function tbl_summary(). The code can seem complex at first, but the outputs look very nice and print to your RStudio Viewer panel as an HTML image.\n\nSummary table\nThe default behavior of tbl_summary() is quite incredible - it takes the columns you provide and creates a summary table in one command. The function prints statistics appropriate to the column class: median and inter-quartile range (IQR) for numeric columns, and counts (%) for categorical columns. Missing values are converted to “Unknown”. Footnotes are added to the bottom to explain the statistics, while the total N is shown at the top.\n\n\nShow the solution\nc19_df %>% \n  select(age, state, male, malaysian, bid) %>%  # keep only the columns of interest\n  tbl_summary()                                 # default\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,1651\n    \n  \n  \n    age\n64 (51, 75)\n    state\n\n        Johor\n4,741 (13%)\n        Kedah\n2,756 (7.4%)\n        Kelantan\n1,428 (3.8%)\n        Melaka\n1,215 (3.3%)\n        Negeri Sembilan\n1,546 (4.2%)\n        Pahang\n1,037 (2.8%)\n        Perak\n2,168 (5.8%)\n        Perlis\n199 (0.5%)\n        Pulau Pinang\n2,085 (5.6%)\n        Sabah\n3,212 (8.6%)\n        Sarawak\n1,796 (4.8%)\n        Selangor\n11,028 (30%)\n        Terengganu\n905 (2.4%)\n        W.P. Kuala Lumpur\n2,861 (7.7%)\n        W.P. Labuan\n159 (0.4%)\n        W.P. Putrajaya\n29 (<0.1%)\n    male\n21,374 (58%)\n    malaysian\n33,130 (89%)\n    bid\n7,910 (21%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\n\n\nAdjustments\nby =\nYou can stratify your table by a column (e.g. by outcome), creating a 2-way table.\nstatistic =\nUse an equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the columns to which that display will apply.\n\n\nShow the solution\nc19_df %>% \n  select(age) %>%               # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age ~ \"{mean} ({sd})\") # print mean of age\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,1651\n    \n  \n  \n    age\n63 (17)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\ndigits =\nAdjust the digits and rounding. Optionally, this can be specified to be for continuous columns only (as below).\nlabel =\nAdjust how the column name should be displayed. Provide the column name and its desired label separated by a tilde. The default is the column name.\nmissing_text =\nAdjust how missing values are displayed. The default is “Unknown”.\ntype =\nThis is used to adjust how many levels of the statistics are shown. The syntax is similar to statistic = in that you provide an equation with columns on the left and a value on the right. Two common scenarios include:\n\ntype = all_categorical() ~ \"categorical\" Forces dichotomous columns (e.g. fever yes/no) to show all levels instead of only the “yes” row\n\ntype = all_continuous() ~ \"continuous2\" Allows multi-line statistics per variable, as shown in a later section\n\n\n\nShow the solution\nc19_df %>% \n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=date_announced-date,\n         days_admitted=date-date_positive,\n         vaccinated=ifelse(is.na(date_dose2), \"unvaccinated\", \"vaccinated\")) %>%\n  select(age, male, malaysian, bid, vaccinated,\n         comorb, days_delay, days_admitted) %>% # keep only columns of interest\n  tbl_summary(     \n    by = malaysian,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      malaysian      ~ \"Nationality\",                           \n      age            ~ \"Age (years)\",\n      male           ~ \"Gender\",\n      bid            ~ \"Brought-in-dead\",\n      comorb         ~ \"Comorbids\",\n      vaccinated     ~ \"Vaccine status\",\n      days_admitted  ~ \"Duration between diagnosis and death (days) \",\n      days_delay     ~ \"Duration between death and announcement (days)\"),\n    missing_text = \"NA\"                                    # how missing values should display\n  )\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0351\n      1, N = 33,1301\n    \n  \n  \n    Age (years)\n49.5 (14.3)\n64.3 (16.1)\n    Gender\n\n\n        0\n1,650 / 4,035 (41%)\n14,141 / 33,130 (43%)\n        1\n2,385 / 4,035 (59%)\n18,989 / 33,130 (57%)\n    Brought-in-dead\n\n\n        0\n1,958 / 4,035 (49%)\n27,297 / 33,130 (82%)\n        1\n2,077 / 4,035 (51%)\n5,833 / 33,130 (18%)\n    Vaccine status\n\n\n        unvaccinated\n3,809 / 4,035 (94%)\n24,229 / 33,130 (73%)\n        vaccinated\n226 / 4,035 (5.6%)\n8,901 / 33,130 (27%)\n    Comorbids\n\n\n        0\n2,175 / 4,035 (54%)\n5,718 / 33,130 (17%)\n        1\n1,860 / 4,035 (46%)\n27,412 / 33,130 (83%)\n    Duration between death and announcement (days)\n15.0 (19.4)\n8.9 (18.2)\n    Duration between diagnosis and death (days) \n4.1 (14.6)\n6.6 (10.0)\n  \n  \n  \n    \n      1 Mean (SD); n / N (%)\n    \n  \n\n\n\n\n\n\nMulti-line stats for continuous variables\nIf you want to print multiple lines of statistics for continuous variables, you can indicate this by setting the type = to “continuous2”. You can combine all of the previously shown elements in one table by choosing which statistics you want to show. To do this you need to tell the function that you want to get a table back by entering the type as “continuous2”. The number of missing values is shown as “Unknown”.\n\n\nShow the solution\nc19_df %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=date_announced-date,\n         days_admitted=date-date_positive) %>%\n  select(age, days_delay, days_admitted) %>% # keep only columns of interest\n  tbl_summary(                               # create summary table\n    type = all_continuous() ~ \"continuous2\", # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                       # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",             # line 2: median and IQR\n      \"{min}, {max}\")                        # line 3: min and max\n    )\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,165\n    \n  \n  \n    age\n\n        Mean (SD)\n63 (17)\n        Median (IQR)\n64 (51, 75)\n        Range\n0, 130\n    days_delay\n\n        Mean (SD)\n10 (18)\n        Median (IQR)\n3 (2, 7)\n        Range\n0, 396\n    days_admitted\n\n        Mean (SD)\n6 (11)\n        Median (IQR)\n4 (0, 9)\n        Range\n0, 724\n  \n  \n  \n\n\n\n\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook"
  },
  {
    "objectID": "data_viz_tutorial.html",
    "href": "data_viz_tutorial.html",
    "title": "Data Visualisation in R- Tutorial",
    "section": "",
    "text": "Call the data in and load packages\n\n\nShow the solution\n#load packages\nrequired_packages <- c(\"tidyverse\", \"rio\", \"here\", \"stringr\", \"lubridate\", \"ggforce\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: rio\n\nLoading required package: here\n\nhere() starts at C:/R/nih_training/readyforR_rtufom2023\n\nLoading required package: ggforce\n\n\nShow the solution\n#call in data\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n\n\n\n\nCall the data in\nCreate a new variable vaccinated that indicates if an individual is fully vaccinated (dose2) or not. (Tip: use mutate and ifelse)\nPlot a scatterplot showing the relationship between age and date. Use the new variable vaccinated variable to color the points using the colour hex #1369FF and #00B556. (Tip: Use the command scale_colour_manual)\nNext try using the date_dose3 instead of date. Anything interesting?\n\n\n\nShow the solution\n#clean data\nc19_df <- c19_df %>% \n  mutate(across(where(is.character), na_if, \"\"),\n         vaccinated= ifelse(is.na(date_dose2), 0, 1))\n\nscatter_plot <- ggplot(data=c19_df) +\n  geom_point(mapping=aes(x=date, y=age, col=factor(vaccinated))) +\n  scale_colour_manual(name=\"Vaccination status\",\n                      values = c(`0`=\"#1369FF\", `1`=\"#00B556\"),\n                      labels = c(`0`=\"Unvaccinated\", `1`=\"Vaccinated\"))\nscatter_plot\n\n\n\n\n\n\nCreate a line chart to represent the cumulative number of vaccinations by dose over time.\nSelect all the date_doseX, and state\nPivot the data into long form (Tip: use the pivot_long function) and count the number of dose given on each date\nComplete the series of dates using complete\nPlot the the different doses by date across time and facet by state\nColour date_dose3= #A3D2D5. Maintain the other 2 colours.\nApply a pre-set theme\n\n\n\nShow the solution\nvaccine_df <- c19_df %>% select(state, date_dose1, date_dose2, date_dose3) %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\"))) %>%\n  pivot_longer(cols = starts_with(\"date_dose\"), \n               names_to = \"dose\", \n               values_to = \"date\", \n               values_drop_na = TRUE) %>%\n  group_by(state, dose, date) %>%\n  summarise(count = n(), .groups = \"drop\") %>%\n  group_by(state, dose) %>% \n  complete(date = seq.Date(min(date, na.rm = TRUE), max(date, na.rm = TRUE), by = \"day\"), fill = list(count = 0))\n\n#plot\nline_plot <- ggplot(data=vaccine_df) +\n  geom_area(mapping=aes(x=date, y=count, fill=dose))+\n  scale_fill_manual(name=\"Vaccination status\",\n                      values = c(\"date_dose1\"=\"#1369FF\", \"date_dose2\"=\"#00B556\", \"date_dose3\"=\"#A3D2D5\"),\n                      labels = c(\"date_dose1\"=\"Dose 1\", \"date_dose2\"=\"Dose 2\", \"date_dose3\"=\"Dose 3\")) +\n  facet_wrap(~state, ncol = 4, scales=\"free_y\")+\n  theme_minimal()\nline_plot\n\n\n\n\n\n\nCall data in\nReplace all empty cells with NA in column brand2\nGroup by state and brand2 and summarise the number of groups in each brand, state\nPlot a box plot on the distribution of deaths by brand2\nTitle should be “Number of Deaths by Vaccine Brand and Date” with x-axis labels of “Vaccine Brand” and y-axis labels of “Number of Deaths” (Tip: Use labs)\n\n\n\nShow the solution\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nc19_df <- c19_df %>%\n  mutate(brand2 = replace_na(brand2, \"Unvax\")) %>%\n  filter(brand2 %in% c(\"AstraZeneca\", \"Pfizer\", \"Sinovac\", \"Unvax\")) %>%\n  group_by(state, brand2) %>%\n  summarise(deaths = n(), .groups = \"drop\")\n\nboxplot_plot <- ggplot(c19_df) +\n  geom_boxplot(aes(x = brand2, y = deaths, col=brand2)) +\n  labs(x = \"Vaccine Brand\", y = \"Number of Deaths\", \n       title = \"Number of Deaths by Vaccine Brand and Date\") +\n  theme_minimal()\nboxplot_plot\n\n\n\n\n\n\nCall in data\nSelect on state, malaysian, bid\nFactorise the variable\nBuild a grouped bar chart by state and bid status\nFacet wrap by malaysian\nTitle should be “Deaths by State, Brought-in-Dead Status, and Malaysian Status” with x-axis labels of “State” and y-axis labels of “Number of Deaths”. Legend label should be “Brought-in-Dead Status”.\nApply theme_minimal and adjust the x-axis text to be perpendicular (90 degrees) to the axis (Tip: Use theme (axis.text.x=element_text()))\nWhat should you change to transform this into a stacked bar chart?\n\n\n\nShow the solution\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nc19_df  <- c19_df %>%\n  mutate(malaysian = if_else(malaysian == 1, \"Malaysian\", \"Non-Malaysian\"),\n         bid = if_else(bid == 1, \"Brought-in-Dead\", \"Hospital Death\")) %>%\n  mutate(across(c(malaysian, bid), factor))  # Convert these columns to factors\n\n# Create the grouped bar chart\nbar_plot <- ggplot(c19_df, aes(x = state, fill = bid)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~malaysian) +\n  labs(x = \"State\", y = \"Number of Deaths\", \n       title = \"Deaths by State, Brought-in-Dead Status, and Malaysian Status\",\n       fill = \"Brought-in-Dead Status\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))  # Rotate x-axis labels for better visibility\nbar_plot\n\n#question 8 remove position=dodge \n\n\n\n\n\n\nEasy peasy lemon squesy- just save all of the above 4 plots. (Tip: use ggsave())\nHow can we change output format, quality, size\n\n\n\nShow the solution\nggsave(\"scatter_plot.png\", scatter_plot)\nggsave(\"line_plot.pdf\", line_plot, dpi=300)\nggsave(\"boxplot_plot.svg\", boxplot_plot, unit=\"px\", height=1080, width = 1920)\nggsave(\"bar_plot.eps\", bar_plot, unit=\"in\", height=3.25, width = 3.25)"
  },
  {
    "objectID": "descriptives_tutorial.html",
    "href": "descriptives_tutorial.html",
    "title": "Descriptive Statistics- Tutorial",
    "section": "",
    "text": "Task 1: Descriptive statistics using tidyverse\nQuestion: Compute the summary statistics (count, mean, standard deviation, minimum, and maximum) of age using tidyverse functions.\nSteps:\n\nInstall and load the tidyverse package.\nFilter the dataset to remove missing values in the “age” column (Note there are no missing values in the dataset- the task is simply meant to simulate the code that would be required if there were).\nUse the summary functions from dplyr to compute the required summary statistics. In this case- count, mean, standard deviation, minimum, and maximum\n\n\n\nShow the solution\n# Step 1\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# Step 2 & 3\nsummary_age <- c19_df %>% filter(!is.na(age)) %>% \n  summarise(\n  count = n(),\n  mean = mean(age),\n  sd = sd(age),\n  min = min(age),\n  max = max(age)\n)\nsummary_age\n\n\n  count     mean       sd min max\n1 37165 62.65809 16.58938   0 130\n\n\n\n\nTask 2: Descriptive statistics using gtsummary\nQuestion: Create a descriptive statistics table for age, male, bid, and malaysian variables using gtsummary.\nSteps:\n\nInstall and load the gtsummary package.\nCreate a subset of the data with the selected variables (Note: Select any five variables).\nUse the tbl_summary() function to compute and display the descriptive statistics.\nStratify by any other selected variable.\n\n\n\nShow the solution\n# Step 1\n#install.packages(\"gtsummary\")\nlibrary(gtsummary)\n\n# Step 2, 3 & 4\ndf_subset <- c19_df %>% \n  select(age, male, bid, malaysian) %>% \n  tbl_summary(by = malaysian)"
  }
]